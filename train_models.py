# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QuuyhiAZ2Ejtvg0NHB56chJvxmNescNR
"""

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression, RandomForestRegressor
import os

# Step 1: Save the dataset to a CSV file
data = """Battery_Capacity_kWh,Range_miles,Weight_kg,Seats,Price
50,200,1500,5,35000
60,250,1700,5,40000
70,300,1800,5,50000
80,350,1900,7,60000
40,150,1400,4,30000
55,220,1600,5,38000
65,280,1750,5,42000
75,320,1850,7,55000
45,180,1450,4,32000
50,200,1600,5,37000
60,240,1650,5,41000
70,290,1700,5,48000
80,330,1900,7,62000
40,160,1400,4,31000
55,210,1550,5,37500
65,270,1700,5,43000
75,310,1800,7,57000
45,170,1400,4,33000
50,210,1600,5,38000
60,260,1650,5,40000
70,280,1750,5,46000
80,340,1900,7,64000
40,180,1450,4,30000
55,230,1600,5,38500
65,250,1700,5,41500
75,300,1800,7,56000
45,160,1400,4,32500
50,190,1600,5,37500
60,270,1700,5,42500
70,310,1800,5,49000
80,360,1900,7,63000
40,150,1450,4,31000
55,220,1600,5,38000
65,240,1700,5,43000
75,280,1800,7,57000
45,180,1450,4,33000
50,210,1600,5,38000
60,250,1650,5,40500
70,320,1750,5,47000
80,330,1900,7,62000
40,160,1400,4,30500
55,200,1600,5,37000
65,260,1700,5,42000
75,300,1800,7,55000
45,170,1450,4,32000
50,200,1600,5,37500
60,270,1700,5,41500
70,310,1750,5,49000
80,340,1900,7,63500"""

file_name = "ev_price_data.csv"
with open(file_name, "w") as file:
    file.write(data)

print(f"Dataset saved as '{file_name}'.")

# Step 2: Initialize Spark session
spark = SparkSession.builder.master("local").appName("EV Price Prediction").getOrCreate()

# Step 3: Load the dataset
df = spark.read.csv(file_name, header=True, inferSchema=True)

# Step 4: Prepare the data
features = ['Battery_Capacity_kWh', 'Range_miles', 'Weight_kg', 'Seats']
assembler = VectorAssembler(inputCols=features, outputCol="features")
df = assembler.transform(df)

# Step 5: Split the data into training and testing datasets
train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)

# Step 6: Train the Linear Regression model
lr = LinearRegression(featuresCol="features", labelCol="Price")
lr_model = lr.fit(train_data)

# Step 7: Train the Random Forest model
rf = RandomForestRegressor(featuresCol="features", labelCol="Price", numTrees=100)
rf_model = rf.fit(train_data)

# Step 8: Save the models
lr_model_path = "linear_regression_ev_model"
rf_model_path = "random_forest_ev_model"

if not os.path.exists(lr_model_path):
    lr_model.save(lr_model_path)
if not os.path.exists(rf_model_path):
    rf_model.save(rf_model_path)

print("Models trained and saved successfully.")

# Step 9: Stop the Spark session
spark.stop()